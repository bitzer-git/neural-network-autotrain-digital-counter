{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Training\n",
    "\n",
    "Target of this code is to train a CNN network to classify images of a digital readout to the digits 0 to 9. Additionally a category \"NaN\" is introduced, to mark images that are not amibiguous.\n",
    "\n",
    "### Preparing the training\n",
    "* First all libraries are loaded\n",
    "    * It is assumed, that they are installed during the Python setup\n",
    "* matplotlib is set to print the output inline in the jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "########### Basic Parameters for Running: ################################\n",
    "    \n",
    "TFliteNamingAndVersion = \"dig1330s3\"   # Used for tflite Filename\n",
    "Training_Percentage = 0.0              # 0.0 = Use all Images for Training\n",
    "Epoch_Anz = 5\n",
    "\n",
    "##########################################################################\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.python import keras\n",
    "from tensorflow.python.keras import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, InputLayer, Conv2D, MaxPool2D, Flatten, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import History \n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from PIL import Image \n",
    "from pathlib import Path\n",
    "\n",
    "loss_ges = np.array([])\n",
    "val_loss_ges = np.array([])\n",
    "\n",
    "%matplotlib inline\n",
    "np.set_printoptions(precision=4)\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training data\n",
    "* The data is expected in the \"Input_dir\"\n",
    "* Inside subdirectories are expected from -1, 0, 1, ... 9 in which the pictures are sorted according to their values (=category)\n",
    "* Picture size must be 20x32 with 3 color channels (RGB)\n",
    "* The filename can be arbitrary\n",
    "\n",
    "* The images are stored in the x_data[]\n",
    "* The expected category for each image in the corresponding y_data[]\n",
    "\n",
    "* The last step is a shuffle (from sklearn.utils) and split the data into training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1684, 32, 20, 3)\n",
      "(1684, 11)\n"
     ]
    }
   ],
   "source": [
    "Input_dir='ziffer_resize'\n",
    "\n",
    "files = glob.glob(Input_dir + '/*.jpg')\n",
    "x_data = []\n",
    "y_data = []\n",
    "\n",
    "for aktfile in files:\n",
    "    base = os.path.basename(aktfile)\n",
    "    target = base[0:1]\n",
    "    if target == \"N\":\n",
    "        category = 10                # NaN does not work --> convert to 10\n",
    "    else:\n",
    "        category = int(target)\n",
    "    test_image = Image.open(aktfile)\n",
    "    test_image = np.array(test_image, dtype=\"float32\")\n",
    "    x_data.append(test_image)\n",
    "    y_data.append(np.array([category]))\n",
    "\n",
    "x_data = np.array(x_data)\n",
    "y_data = np.array(y_data)\n",
    "y_data = to_categorical(y_data, 11)\n",
    "print(x_data.shape)\n",
    "print(y_data.shape)\n",
    "\n",
    "x_data, y_data = shuffle(x_data, y_data)\n",
    "\n",
    "if (Training_Percentage > 0):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=Training_Percentage)\n",
    "else:\n",
    "    X_train = x_data\n",
    "    y_train = y_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model\n",
    "\n",
    "The layout of the network ist a typcial CNN network with alternating **Conv2D** and **MaxPool2D** layers. Finished after **flattening** with additional **Dense** layer.\n",
    "\n",
    "#### Important\n",
    "* Shape of the input layer: (32, 20, 3)\n",
    "* Number of output layers: 11\n",
    "* As loss function \"categorical_crossentropy\" is choosen, as it is a categories task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization (BatchNo (None, 32, 20, 3)         12        \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 32, 20, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 10, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 5, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 11)                1419      \n",
      "=================================================================\n",
      "Total params: 53,719\n",
      "Trainable params: 53,713\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(BatchNormalization(input_shape=(32,20,3)))\n",
    "model.add(Conv2D(32, (3, 3), padding='same', activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(32, (3, 3), padding='same', activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(32, (3, 3), padding='same', activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,activation=\"relu\"))\n",
    "model.add(Dense(11, activation = \"softmax\"))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=tf.keras.optimizers.Adadelta(learning_rate=1.0, rho=0.95), metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "The input pictures are randomly scattered for brightness, pixel shift variations and rotation angle. This is implemented with a ImageDataGenerator.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "421/421 [==============================] - 2s 3ms/step - loss: 2.2266 - accuracy: 0.2892\n",
      "Epoch 2/5\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 1.5887 - accuracy: 0.4874\n",
      "Epoch 3/5\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 1.1598 - accuracy: 0.6310\n",
      "Epoch 4/5\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.9886 - accuracy: 0.6733\n",
      "Epoch 5/5\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.8118 - accuracy: 0.7512\n"
     ]
    }
   ],
   "source": [
    "Batch_Size = 4\n",
    "Shift_Range = 1\n",
    "Brightness_Range = 0.3\n",
    "Rotation_Angle = 10\n",
    "ZoomRange = 0.4\n",
    "\n",
    "datagen = ImageDataGenerator(width_shift_range=[-Shift_Range,Shift_Range], \n",
    "                             height_shift_range=[-Shift_Range,Shift_Range],\n",
    "                             brightness_range=[1-Brightness_Range,1+Brightness_Range],\n",
    "                             zoom_range=[1-ZoomRange, 1+ZoomRange],\n",
    "                             rotation_range=Rotation_Angle)\n",
    "\n",
    "if (Training_Percentage > 0):\n",
    "    train_iterator = datagen.flow(x_data, y_data, batch_size=Batch_Size)\n",
    "    validation_iterator = datagen.flow(X_test, y_test, batch_size=Batch_Size)\n",
    "    history = model.fit(train_iterator, validation_data = validation_iterator, epochs = Epoch_Anz)\n",
    "else:\n",
    "    train_iterator = datagen.flow(x_data, y_data, batch_size=Batch_Size)\n",
    "    history = model.fit(train_iterator, epochs = Epoch_Anz)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learing result\n",
    " \n",
    "* Visualization of the training and validation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_ges = np.append(loss_ges, history.history['loss'])\n",
    "plt.semilogy(history.history['loss'])\n",
    "\n",
    "if (Training_Percentage > 0):\n",
    "    val_loss_ges = np.append(val_loss_ges, history.history['val_loss'])\n",
    "    plt.semilogy(history.history['val_loss'])\n",
    "\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','eval'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the model by hand\n",
    "\n",
    "* The following code uses the trained model to check the deviation for each picture.\n",
    "* x-axis walks through each pixel, y-axis shows the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check each image for expected and deviation\n",
    "* setting the switch \"only_deviation = true\" will only print the images for which the classification and the CNN-result deviates\n",
    "\n",
    "The output contains the following information:\n",
    "\n",
    "| Filename      | Expected Category           | Predicted Category        |\n",
    "|------------- |:-----------------------------:|--------------|\n",
    "| ziffer_sortiert_resize_NaN/5\\Ziffer_4_0034.jpg | 4  | -1 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6368/2916101208.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Result'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "Input_dir='ziffer_sortiert_resize'\n",
    "res = []\n",
    "only_deviation = True\n",
    "show_wrong_image = True\n",
    "\n",
    "files = glob.glob(Input_dir + '/*.jpg')\n",
    "\n",
    "for aktfile in files:\n",
    "    base = os.path.basename(aktfile)\n",
    "    target = base[0:1]\n",
    "    if target == \"N\":\n",
    "        zw1 = -1\n",
    "    else:\n",
    "        zw1 = int(target)\n",
    "    expected_class = zw1\n",
    "    image_in = Image.open(aktfile)\n",
    "    test_image = np.array(image_in, dtype=\"float32\")\n",
    "    img = np.reshape(test_image,[1,32,20,3])\n",
    "    classes = np.argmax(model.predict(img), axis=-1)\n",
    "    classes = classes[0]\n",
    "    if classes == 10: \n",
    "        classes = -1\n",
    "    zw2 = classes\n",
    "    zw3 = zw2 - zw1\n",
    "    res.append(np.array([zw1, zw2, zw3]))\n",
    "    if only_deviation == True:\n",
    "        if str(classes) != str(expected_class):\n",
    "            print(aktfile + \" \" + str(expected_class) +  \" \" + str(classes))\n",
    "            if show_wrong_image == True:\n",
    "                display(image_in)\n",
    "    else:\n",
    "        print(aktfile + \" \" + aktsubdir +  \" \" + str(classes))\n",
    "        \n",
    "\n",
    "res = np.asarray(res)\n",
    "\n",
    "\n",
    "plt.plot(res[:,0])\n",
    "plt.plot(res[:,1])\n",
    "plt.title('Result')\n",
    "plt.ylabel('Digital Value')\n",
    "plt.xlabel('#Picture')\n",
    "plt.legend(['real','model'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model\n",
    "\n",
    "* Save the model to the file with the \"h5\" file format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FileName = TFliteNamingAndVersion\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "open(FileName + \".tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FileName = TFliteNamingAndVersion + \"q.tflite\"\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def representative_dataset():\n",
    "    for n in range(x_data[0].size):\n",
    "      data = np.expand_dims(x_data[5], axis=0)\n",
    "      yield [data.astype(np.float32)]\n",
    "        \n",
    "converter2 = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter2.representative_dataset = representative_dataset\n",
    "converter2.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter2.representative_dataset = representative_dataset\n",
    "tflite_quant_model = converter2.convert()\n",
    "\n",
    "open(FileName, \"wb\").write(tflite_quant_model)\n",
    "print(FileName)\n",
    "Path(FileName).stat().st_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the images shows, that this are border line images, which can be interpreted as a good digit or a faulty one."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
