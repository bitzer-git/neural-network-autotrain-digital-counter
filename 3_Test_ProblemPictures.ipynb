{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test der Netzqualität mittels der Trainingsbilder\n",
    "\n",
    "Das im ersten Teil erzeugte und gespeicherte Netz wird hier getestet:\n",
    "\n",
    "0. Vorbereitung (Laden der Bibliotheken und Einstellungen)\n",
    "1. Laden des neuronalen Netzes\n",
    "2. Test anhand der Trainingsdaten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0) Vorbereitung\n",
    "\n",
    "##### Modelname\n",
    "ACHTUNG: hier muss der korrekte Modelname definiert werden, wie er auch im letzten Skript verwendet wurde.\n",
    "\n",
    "##### Bibliotheken\n",
    "Laden der notwendigen Bibliotheken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "\n",
    "ModelNameAndVersion = \"dig-s0-q\"\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "from PIL import Image \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.lite as tflite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Laden des neuronalen Netzes\n",
    "\n",
    "Mittels der Funktion \"load_model\" wird das Model geladen und anschließend die Architektur im Überblick nochmals ausgegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load quantized TFLite model\n",
    "tflite_interpreter_quant = tflite.Interpreter(model_path='a_output_actual/' + ModelNameAndVersion + '.tflite')\n",
    "tflite_interpreter_quant.allocate_tensors()\n",
    "\n",
    "# Learn about its input and output details\n",
    "input_details = tflite_interpreter_quant.get_input_details()\n",
    "output_details = tflite_interpreter_quant.get_output_details()\n",
    "\n",
    "# Resize input and output tensors to handle batch of 32 images\n",
    "#tflite_interpreter_quant.resize_tensor_input(input_details[0]['index'], (32, 224, 224, 3))\n",
    "#tflite_interpreter_quant.resize_tensor_input(output_details[0]['index'], (32, 5))\n",
    "#tflite_interpreter_quant.allocate_tensors()\n",
    "\n",
    "input_details = tflite_interpreter_quant.get_input_details()\n",
    "output_details = tflite_interpreter_quant.get_output_details()\n",
    "\n",
    "print(\"== Input details ==\")\n",
    "print(\"name:\", input_details[0]['name'])\n",
    "print(\"shape:\", input_details[0]['shape'])\n",
    "print(\"type:\", input_details[0]['dtype'])\n",
    "\n",
    "print(\"\\n== Output details ==\")\n",
    "print(\"name:\", output_details[0]['name'])\n",
    "print(\"shape:\", output_details[0]['shape'])\n",
    "print(\"type:\", output_details[0]['dtype'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#model = keras.models.load_model('a_output_actual/' + ModelNameAndVersion)\n",
    "\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Test anhand der Trainingsdaten\n",
    "\n",
    "Einen guten Eindruck über die Qualität liefert eine Iteration über alle Trainingsbilder. Dazu wird jedes Bild (ACHTUNG: schon in der Zielauflösung) einzeln geladen und durch das neuronale Netz berechnet. SOLL- und IST-Werte werden zum einen in einem Array gespeichert. \n",
    "\n",
    "Wenn diese nicht identisch sind, werden die entsprechenden Bilder und die zugehörigen Daten direkt ausgegeben. Das hilft sehr bei der Fehlersuche, denn häufige hat man noch einen Fehler in der Klassifizierung oder erkennt, dass das Bild doch so schlecht ist, dass es besser nicht verwendet werden sollte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Input_dir = 'ziffer_problems_raw'\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "res = []\n",
    "\n",
    "files = glob.glob(Input_dir + '/*.jpg')\n",
    "\n",
    "for aktfile in files:\n",
    "    Dateiname      = os.path.basename(aktfile)    # Dateiname\n",
    "    Classification_SOLL = Dateiname[0:1]          # Die erste Ziffer entspricht der Zugehörigen Klassifizierung\n",
    "    if Classification_SOLL == \"N\":\n",
    "        Classification_SOLL = 10                  # NaN does not work --> convert to 10\n",
    "    else:\n",
    "        Classification_SOLL = int(Classification_SOLL)\n",
    "\n",
    "    test_image_in = Image.open(aktfile)\n",
    "    test_image = test_image_in.resize((20, 32), Image.NEAREST)\n",
    "    test_image = np.array(test_image, dtype=\"float32\")\n",
    "    img = np.reshape(test_image,[1,32,20,3])\n",
    "    \n",
    "    tflite_interpreter_quant.set_tensor(input_details[0]['index'], img)\n",
    "    tflite_interpreter_quant.invoke()\n",
    "    tflite_q_model_predictions = tflite_interpreter_quant.get_tensor(output_details[0]['index'])\n",
    "    \n",
    "    Classification_IST = np.argmax(tflite_q_model_predictions)\n",
    "#    Classification_IST = classes[0]\n",
    "    \n",
    "    res.append(np.array([Classification_SOLL, Classification_IST]))\n",
    "\n",
    "    print(str(tflite_q_model_predictions) + \" Soll: \" + str(Classification_SOLL) +  \" IST: \" + str(Classification_IST) + \" \" + Dateiname)\n",
    "    \n",
    "    if Classification_SOLL != Classification_IST:\n",
    "        display(test_image_in)\n",
    "\n",
    "res = np.asarray(res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisierung über die gesamten Trainingsbilder\n",
    "\n",
    "Im vorherigen Schritt wurde für jedes Bild sowohl Soll, wie auch IST-Wert gespeichert. Hier wird über die einzelnen Bilder beide Werte in einem Diagramm dargestellt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(res[:,0])\n",
    "plt.plot(res[:,1])\n",
    "plt.title('Result')\n",
    "plt.ylabel('Digital Value')\n",
    "plt.xlabel('#Picture')\n",
    "plt.legend(['SOLL','IST'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
